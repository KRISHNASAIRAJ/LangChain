# Introduction

LangChain is a framework for developing applications powered by language models.

It provides a standard interface for accessing language models, along with a collection of chains for common language applications.

Developers can use LangChain to build applications that use language models to interact with data, solve problems, or generate text.

It supports Productionization where we will be using LangSmith to deploy the applications.

![LangChain](https://python.langchain.com/svg/langchain_stack_112024_dark.svg)

LangChain implements a standard interface for large language models and related technologies, such as embedding models and vector stores, and integrates with hundreds of providers.

A chat model is a language model that is trained to generate responses that are contextually relevant to a given conversation.

The model is trained on a large corpus of text data, which includes a wide range of conversations and topics. The model learns to generate responses that are coherent and relevant to the conversation, and that can be used to answer questions or provide information.

The model is trained using a technique called unsupervised learning, which means that it learns from the data without being explicitly told which responses are correct or incorrect. This allows the model to generate responses that are not only coherent and relevant, but also diverse and creative.

LangSmith is a cloud-based platform that allows developers to easily deploy and manage their LangChain applications. It provides a simple and intuitive interface for building and deploying LangChain applications, and supports a wide range of language models and other tools.